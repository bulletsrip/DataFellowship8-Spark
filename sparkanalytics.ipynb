{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up Pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pyspark in /home/yuditya/spark/python (3.3.0)\n",
      "Requirement already satisfied: py4j==0.10.9.5 in /home/yuditya/.local/lib/python3.7/site-packages (from pyspark) (0.10.9.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install -q findspark\n",
    "!pip install pyspark\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/10 17:58:21 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master('local') \\\n",
    "    .appName('SparkAnalytics') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-12-10 17:58:26--  https://d37ci6vzurychx.cloudfront.net/trip-data/fhv_tripdata_2021-02.parquet\n",
      "Resolving d37ci6vzurychx.cloudfront.net (d37ci6vzurychx.cloudfront.net)... 18.161.108.141, 18.161.108.231, 18.161.108.184, ...\n",
      "Connecting to d37ci6vzurychx.cloudfront.net (d37ci6vzurychx.cloudfront.net)|18.161.108.141|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 10645466 (10M) [binary/octet-stream]\n",
      "Saving to: ‘fhv_tripdata_2021-02.parquet.1’\n",
      "\n",
      "fhv_tripdata_2021-0 100%[===================>]  10.15M  2.77MB/s    in 4.2s    \n",
      "\n",
      "2022-12-10 17:58:31 (2.44 MB/s) - ‘fhv_tripdata_2021-02.parquet.1’ saved [10645466/10645466]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://d37ci6vzurychx.cloudfront.net/trip-data/fhv_tripdata_2021-02.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Table Schema\n",
    "## Spark includes the ability to read and write from a large number of data sources using InferSchema, this will automatically guess the data types for each field.\n",
    "## Howerever, you should use StructType to define the schema while reading a file for more efficient way to improve the Spark performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = types.StructType(\n",
    "    [\n",
    "        types.StructField('dispatching_base_num', types.StringType(), True),\n",
    "        types.StructField('pickup_datetime', types.TimestampType(), True),\n",
    "        types.StructField('dropoff_datetime', types.TimestampType(), True),\n",
    "        types.StructField('PULocationID', types.DoubleType(), True),\n",
    "        types.StructField('DOLocationID', types.DoubleType(), True),\n",
    "        types.StructField('SR_Flag', types.IntegerType(), True),\n",
    "        types.StructField('Affiliated_base_number', types.StringType(), True)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .schema(schema) \\\n",
    "    .parquet('fhv_tripdata_2021-02.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:=============================>                             (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "|dispatching_base_num|    pickup_datetime|   dropoff_datetime|PULocationID|DOLocationID|SR_Flag|Affiliated_base_number|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "|              B00013|2021-02-01 07:01:00|2021-02-01 08:33:00|        null|        null|   null|                B00014|\n",
      "|     B00021         |2021-02-01 07:55:40|2021-02-01 08:06:20|       173.0|        82.0|   null|       B00021         |\n",
      "|     B00021         |2021-02-01 07:14:03|2021-02-01 07:28:37|       173.0|        56.0|   null|       B00021         |\n",
      "|     B00021         |2021-02-01 07:27:48|2021-02-01 07:35:45|        82.0|       129.0|   null|       B00021         |\n",
      "|              B00037|2021-02-01 07:12:50|2021-02-01 07:26:38|        null|       225.0|   null|                B00037|\n",
      "|              B00037|2021-02-01 07:00:37|2021-02-01 07:09:35|        null|        61.0|   null|                B00037|\n",
      "|              B00112|2021-02-01 07:30:25|2021-02-01 07:57:23|        null|        26.0|   null|                B00112|\n",
      "|              B00149|2021-02-01 07:43:16|2021-02-01 08:03:16|        null|        72.0|   null|                B00149|\n",
      "|              B00221|2021-02-01 07:20:45|2021-02-01 07:21:15|        null|       244.0|   null|                B00221|\n",
      "|              B00225|2021-02-01 07:23:27|2021-02-01 07:55:46|        null|       169.0|   null|                B00225|\n",
      "|              B00225|2021-02-01 07:10:38|2021-02-01 07:50:15|        null|       161.0|   null|                B02872|\n",
      "|              B00254|2021-02-01 07:05:46|2021-02-01 07:40:41|        13.0|       182.0|   null|                B00254|\n",
      "|              B00254|2021-02-01 07:14:25|2021-02-01 07:24:56|       152.0|       244.0|   null|                B02872|\n",
      "|              B00256|2021-02-01 07:30:43|2021-02-01 08:32:39|        null|        null|   null|                B00256|\n",
      "|              B00256|2021-02-01 07:39:11|2021-02-01 08:18:44|        null|        null|   null|                B00256|\n",
      "|              B00256|2021-02-01 07:33:24|2021-02-01 08:23:44|        null|        null|   null|                B00256|\n",
      "|              B00256|2021-02-01 07:05:19|2021-02-01 07:24:40|        null|        null|   null|                B00256|\n",
      "|              B00271|2021-02-01 07:04:07|2021-02-01 08:03:03|        null|       265.0|   null|                B00271|\n",
      "|              B00271|2021-02-01 07:07:13|2021-02-01 07:08:49|        null|       237.0|   null|                B00271|\n",
      "|              B00310|2021-02-01 07:11:21|2021-02-01 07:15:44|        null|       248.0|   null|                B00310|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Analysis using Spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## createOrReplaceTempView() is used when you wanted to store the table for a specific spark session. Once created you can use it to run SQL queries.\n",
    "df.createOrReplaceTempView(\"fhv_trip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### How many taxi trips were there on February 15?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 2:=======================================>                   (2 + 1) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|taxi_trips_15_feb|\n",
      "+-----------------+\n",
      "|            35709|\n",
      "+-----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "taxi_trips_15_feb = spark.sql(\"\"\"\n",
    "with trips_15_feb as \n",
    "(SELECT\n",
    "    *\n",
    "FROM \n",
    "    fhv_trip\n",
    "WHERE\n",
    "    to_date(pickup_datetime) = '2021-02-15'\n",
    ")\n",
    "SELECT\n",
    "    COUNT(1) as taxi_trips_15_feb\n",
    "FROM \n",
    "    trips_15_feb\n",
    "WHERE\n",
    "    to_date(pickup_datetime) = '2021-02-15'\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Find the longest trip for each day!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 14:=============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+-----------------+\n",
      "|    pickup_datetime|   dropoff_datetime|duration_in_hours|\n",
      "+-------------------+-------------------+-----------------+\n",
      "|2021-02-05 01:45:00|2021-04-23 02:24:00|          1848.65|\n",
      "|2021-02-01 15:00:00|2021-03-05 18:30:00|            771.5|\n",
      "|2021-02-01 19:00:00|2021-03-05 18:29:00|           767.48|\n",
      "|2021-02-25 22:00:00|2021-03-26 00:49:00|           674.82|\n",
      "|2021-02-23 20:30:00|2021-03-23 21:02:00|           672.53|\n",
      "|2021-02-04 00:25:00|2021-03-03 19:39:53|           667.25|\n",
      "|2021-02-04 03:59:00|2021-02-24 04:31:15|           480.54|\n",
      "|2021-02-04 03:59:00|2021-02-24 04:31:15|           480.54|\n",
      "|2021-02-04 03:59:00|2021-02-24 04:31:15|           480.54|\n",
      "|2021-02-27 19:00:00|2021-03-11 15:44:00|           284.73|\n",
      "|2021-02-28 17:00:00|2021-03-11 15:43:00|           262.72|\n",
      "|2021-02-28 19:00:00|2021-03-11 15:42:00|            260.7|\n",
      "|2021-02-01 16:20:08|2021-02-12 00:43:59|            248.4|\n",
      "|2021-02-15 21:20:52|2021-02-26 01:51:01|            244.5|\n",
      "|2021-02-22 21:07:14|2021-03-03 21:48:46|           216.69|\n",
      "|2021-02-08 12:10:48|2021-02-15 01:15:43|           157.08|\n",
      "|2021-02-19 19:45:10|2021-02-26 01:57:19|            150.2|\n",
      "|2021-02-13 20:16:55|2021-02-19 16:39:36|           140.38|\n",
      "|2021-02-13 20:16:55|2021-02-19 16:39:36|           140.38|\n",
      "|2021-02-16 11:41:56|2021-02-19 19:58:02|            80.27|\n",
      "+-------------------+-------------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "taxi_longest_trips = spark.sql(\"\"\"\n",
    "                              SELECT\n",
    "                                  pickup_datetime, dropoff_datetime,\n",
    "                                  ROUND(((unix_timestamp(dropoff_datetime) - unix_timestamp(pickup_datetime))/3600),2) AS duration_in_hours\n",
    "                              FROM fhv_trip\n",
    "                              SORT BY\n",
    "                                  duration_in_hours DESC\n",
    "                              \"\"\")\n",
    "\n",
    "taxi_longest_trips.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Find Top 5 Most frequent `dispatching_base_num` ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|dispatching_base_num|amount|\n",
      "+--------------------+------+\n",
      "|              B00856| 35077|\n",
      "|              B01312| 33089|\n",
      "|              B01145| 31114|\n",
      "|              B02794| 30397|\n",
      "|              B03016| 29794|\n",
      "+--------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "most_dispatching_base_num = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "          dispatching_base_num,\n",
    "          COUNT(1) as amount\n",
    "    FROM \n",
    "          fhv_trip\n",
    "    GROUP BY\n",
    "          1\n",
    "    ORDER BY\n",
    "          2 DESC\n",
    "    LIMIT \n",
    "          5\n",
    "\"\"\")\n",
    "\n",
    "most_dispatching_base_num.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Find Top 5 Most common location pairs (PUlocationID and DOlocationID)\n",
    "## Location name is in another file 'taxi_zone_lookup', we need to import in and join into main table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-12-10 18:45:01--  https://d37ci6vzurychx.cloudfront.net/misc/taxi+_zone_lookup.csv\n",
      "Resolving d37ci6vzurychx.cloudfront.net (d37ci6vzurychx.cloudfront.net)... 18.161.108.77, 18.161.108.231, 18.161.108.141, ...\n",
      "Connecting to d37ci6vzurychx.cloudfront.net (d37ci6vzurychx.cloudfront.net)|18.161.108.77|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 12322 (12K) [text/csv]\n",
      "Saving to: ‘taxi+_zone_lookup.csv’\n",
      "\n",
      "taxi+_zone_lookup.c 100%[===================>]  12.03K  --.-KB/s    in 0.05s   \n",
      "\n",
      "2022-12-10 18:45:05 (222 KB/s) - ‘taxi+_zone_lookup.csv’ saved [12322/12322]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Download Dataset\n",
    "\n",
    "!wget https://d37ci6vzurychx.cloudfront.net/misc/taxi+_zone_lookup.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Defining Table Schema\n",
    "taxi_zones_schema = types.StructType([\n",
    "    types.StructField('LocationID', types.IntegerType(), True),\n",
    "    types.StructField('Borough', types.StringType(), True),\n",
    "    types.StructField('Zone', types.StringType(), True),\n",
    "    types.StructField('service_zone', types.StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_zones_df = spark.read.option('header', 'true').schema(taxi_zones_schema).csv('taxi+_zone_lookup.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------------------+------------+\n",
      "|LocationID|      Borough|                Zone|service_zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "|         1|          EWR|      Newark Airport|         EWR|\n",
      "|         2|       Queens|         Jamaica Bay|   Boro Zone|\n",
      "|         3|        Bronx|Allerton/Pelham G...|   Boro Zone|\n",
      "|         4|    Manhattan|       Alphabet City| Yellow Zone|\n",
      "|         5|Staten Island|       Arden Heights|   Boro Zone|\n",
      "|         6|Staten Island|Arrochar/Fort Wad...|   Boro Zone|\n",
      "|         7|       Queens|             Astoria|   Boro Zone|\n",
      "|         8|       Queens|        Astoria Park|   Boro Zone|\n",
      "|         9|       Queens|          Auburndale|   Boro Zone|\n",
      "|        10|       Queens|        Baisley Park|   Boro Zone|\n",
      "|        11|     Brooklyn|          Bath Beach|   Boro Zone|\n",
      "|        12|    Manhattan|        Battery Park| Yellow Zone|\n",
      "|        13|    Manhattan|   Battery Park City| Yellow Zone|\n",
      "|        14|     Brooklyn|           Bay Ridge|   Boro Zone|\n",
      "|        15|       Queens|Bay Terrace/Fort ...|   Boro Zone|\n",
      "|        16|       Queens|             Bayside|   Boro Zone|\n",
      "|        17|     Brooklyn|             Bedford|   Boro Zone|\n",
      "|        18|        Bronx|        Bedford Park|   Boro Zone|\n",
      "|        19|       Queens|           Bellerose|   Boro Zone|\n",
      "|        20|        Bronx|             Belmont|   Boro Zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "taxi_zones_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Schema for Pick Up Zone\n",
    "Pickup_table = taxi_zones_df \\\n",
    "    .withColumnRenamed('Zone', 'PickUp_Zone') \\\n",
    "    .withColumnRenamed('LocationID', 'PickUp_Location_ID') \\\n",
    "    .withColumnRenamed('Borough', 'PickUP_Borough') \\\n",
    "    .drop('service_zone')\n",
    "\n",
    "### Schema for Drop Off Zone\n",
    "Dropoff_table = taxi_zones_df \\\n",
    "    .withColumnRenamed('Zone', 'DropOff_Zone') \\\n",
    "    .withColumnRenamed('LocationID', 'DropOff_Location_ID') \\\n",
    "    .withColumnRenamed('Borough', 'DropOff_Borough') \\\n",
    "    .drop('service_zone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join fhv_trip table with the table taxi_zone table\n",
    "join_test = df.join(Pickup_table, df.PULocationID == Pickup_table.PickUp_Location_ID)\n",
    "df_join = join_test.join(Dropoff_table, join_test.DOLocationID == Dropoff_table.DropOff_Location_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+------------------+--------------+------------+-------------------+---------------+---------------+\n",
      "|dispatching_base_num|    pickup_datetime|   dropoff_datetime|PULocationID|DOLocationID|SR_Flag|Affiliated_base_number|PickUp_Location_ID|PickUP_Borough| PickUp_Zone|DropOff_Location_ID|DropOff_Borough|   DropOff_Zone|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+------------------+--------------+------------+-------------------+---------------+---------------+\n",
      "|     B00021         |2021-02-01 07:55:40|2021-02-01 08:06:20|       173.0|        82.0|   null|       B00021         |               173|        Queens|North Corona|                 82|         Queens|       Elmhurst|\n",
      "|     B00021         |2021-02-01 07:14:03|2021-02-01 07:28:37|       173.0|        56.0|   null|       B00021         |               173|        Queens|North Corona|                 56|         Queens|         Corona|\n",
      "|     B00021         |2021-02-01 07:27:48|2021-02-01 07:35:45|        82.0|       129.0|   null|       B00021         |                82|        Queens|    Elmhurst|                129|         Queens|Jackson Heights|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+------------------+--------------+------------+-------------------+---------------+---------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_join.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join.createOrReplaceTempView(\"location_pairs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 39:======================================>                   (2 + 1) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+\n",
      "|           zone_pair|total_count|\n",
      "+--------------------+-----------+\n",
      "|Saint George/New ...|       2374|\n",
      "|Stapleton/Saint G...|       2112|\n",
      "|Jackson Heights/J...|       1902|\n",
      "|     Astoria/Astoria|       1829|\n",
      "|Old Astoria/Old A...|       1736|\n",
      "+--------------------+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "location_pairs = spark.sql(\"\"\"\n",
    "SELECT\n",
    "    CONCAT(coalesce(PickUp_Zone, 'Unknown'), '/', coalesce(DropOff_Zone, 'Unknown')) AS zone_pair,\n",
    "    COUNT(1) as total_count\n",
    "FROM\n",
    "    location_pairs\n",
    "GROUP BY\n",
    "    1\n",
    "ORDER BY\n",
    "    2 DESC\n",
    "LIMIT\n",
    "    5\n",
    ";\n",
    "\"\"\")\n",
    "\n",
    "location_pairs.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
